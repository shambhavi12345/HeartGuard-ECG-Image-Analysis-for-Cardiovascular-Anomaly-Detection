{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ca4192a-19e4-4791-bebc-d0717cd97099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FireFly\\AppData\\Local\\Temp\\ipykernel_10204\\650832284.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader, Subset, WeightedRandomSampler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da6a95a5-e8fb-47bd-85c4-0322d40a0e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR     = r\"D:\\res_work\\ECG_analysis_for_CVD\\processed_images_green\"\n",
    "NUM_CLASSES  = 4\n",
    "BATCH_SIZE   = 8       # per-GPU batch\n",
    "ACCUM_STEPS  = 4       # effective batch = 32\n",
    "TOTAL_EPOCHS = 50\n",
    "LR_HEAD      = 1e-3\n",
    "LR_FEAT      = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "TRAIN_RATIO  = 0.7\n",
    "TEST_RATIO   = 0.2\n",
    "VAL_RATIO    = 0.1\n",
    "PATIENCE     = 10      # early stopping patience\n",
    "DROP_PROB    = 0.5      # dropout probability\n",
    "MIXUP_ALPHA  = 0.4      # mixup alpha\n",
    "SMOOTHING    = 0.1      # label smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd5e3041-90dd-4003-9b8c-54790949940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8,1.0)),\n",
    "    transforms.RandAugment(num_ops=2, magnitude=9),\n",
    "    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02,0.15), ratio=(0.3,3.3)),\n",
    "    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225]),\n",
    "])\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ef8c259-e5ba-4e13-a803-6dafa21b8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ds = datasets.ImageFolder(DATA_DIR)\n",
    "N = len(full_ds)\n",
    "n_train = int(TRAIN_RATIO * N)\n",
    "n_test  = int(TEST_RATIO  * N)\n",
    "n_val   = N - n_train - n_test\n",
    "\n",
    "g = torch.Generator().manual_seed(42)\n",
    "perm = torch.randperm(N, generator=g).tolist()\n",
    "train_idx = perm[:n_train]\n",
    "test_idx  = perm[n_train:n_train+n_test]\n",
    "val_idx   = perm[n_train+n_test:]\n",
    "\n",
    "train_targets = [full_ds.targets[i] for i in train_idx]\n",
    "class_counts  = np.bincount(train_targets, minlength=NUM_CLASSES)\n",
    "class_weights = 1. / class_counts\n",
    "sample_weights = [class_weights[t] for t in train_targets]\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "train_ds = Subset(datasets.ImageFolder(DATA_DIR, transform=train_tf), train_idx)\n",
    "val_ds   = Subset(datasets.ImageFolder(DATA_DIR, transform=val_tf),   val_idx)\n",
    "test_ds  = Subset(datasets.ImageFolder(DATA_DIR, transform=val_tf),   test_idx)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=4)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,     num_workers=4)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,     num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c30fc3f0-15c2-4cac-97e6-b58e68991d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "# Freeze early layers\n",
    "for p in base_model.features[:16].parameters(): p.requires_grad = False\n",
    "# Unfreeze last conv block\n",
    "for p in base_model.features[16:].parameters(): p.requires_grad = True\n",
    "\n",
    "# Replace classifier head\n",
    "in_features = base_model.classifier[0].in_features\n",
    "base_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(DROP_PROB),\n",
    "    nn.Linear(in_features, 512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(DROP_PROB),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(DROP_PROB),\n",
    "    nn.Linear(256, NUM_CLASSES)\n",
    ")\n",
    "model = base_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77b79b54-7970-485c-a4b4-2d81a055b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=MIXUP_ALPHA):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    return mixed_x, y, y[index], lam\n",
    "\n",
    "def mixup_criterion(crit, pred, y_a, y_b, lam):\n",
    "    return lam * crit(pred, y_a) + (1 - lam) * crit(pred, y_b)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=SMOOTHING)\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': model.features[16:].parameters(), 'lr': LR_FEAT},\n",
    "    {'params': model.classifier.parameters(),    'lr': LR_HEAD}\n",
    "], weight_decay=WEIGHT_DECAY)\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=[LR_FEAT, LR_HEAD],\n",
    "    total_steps=TOTAL_EPOCHS * len(train_loader),\n",
    "    pct_start=0.1,\n",
    "    anneal_strategy='cos'\n",
    ")\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=PATIENCE):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_acc):\n",
    "        if self.best_score is None or val_acc > self.best_score:\n",
    "            self.best_score = val_acc\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "early_stopper = EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f62cd9a-a515-41e7-aa12-ce1e1593b79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FireFly\\AppData\\Local\\Temp\\ipykernel_10204\\3528197656.py:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\FireFly\\AppData\\Local\\Temp\\ipykernel_10204\\3528197656.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train loss=0.1739, acc=28.85% | Val loss=0.1670, acc=52.13%\n",
      " → New best model saved!\n",
      "Epoch 2/50 | Train loss=0.1612, acc=34.57% | Val loss=0.1383, acc=61.70%\n",
      " → New best model saved!\n",
      "Epoch 3/50 | Train loss=0.1482, acc=41.35% | Val loss=0.1070, acc=76.60%\n",
      " → New best model saved!\n",
      "Epoch 4/50 | Train loss=0.1366, acc=47.33% | Val loss=0.0937, acc=85.11%\n",
      " → New best model saved!\n",
      "Epoch 5/50 | Train loss=0.1469, acc=40.87% | Val loss=0.1169, acc=68.09%\n",
      "Epoch 6/50 | Train loss=0.1293, acc=47.25% | Val loss=0.0847, acc=94.68%\n",
      " → New best model saved!\n",
      "Epoch 7/50 | Train loss=0.1210, acc=49.46% | Val loss=0.0929, acc=86.17%\n",
      "Epoch 8/50 | Train loss=0.1224, acc=53.05% | Val loss=0.0780, acc=89.36%\n",
      "Epoch 9/50 | Train loss=0.1164, acc=52.77% | Val loss=0.0710, acc=92.55%\n",
      "Epoch 10/50 | Train loss=0.1156, acc=55.38% | Val loss=0.0842, acc=82.98%\n",
      "Epoch 11/50 | Train loss=0.1179, acc=54.19% | Val loss=0.0727, acc=92.55%\n",
      "Epoch 12/50 | Train loss=0.1107, acc=56.52% | Val loss=0.0761, acc=91.49%\n",
      "Epoch 13/50 | Train loss=0.1044, acc=54.25% | Val loss=0.0620, acc=95.74%\n",
      " → New best model saved!\n",
      "Epoch 14/50 | Train loss=0.1024, acc=58.97% | Val loss=0.0578, acc=97.87%\n",
      " → New best model saved!\n",
      "Epoch 15/50 | Train loss=0.1017, acc=57.20% | Val loss=0.0579, acc=97.87%\n",
      "Epoch 16/50 | Train loss=0.0974, acc=59.05% | Val loss=0.0624, acc=97.87%\n",
      "Epoch 17/50 | Train loss=0.1043, acc=59.04% | Val loss=0.0571, acc=98.94%\n",
      " → New best model saved!\n",
      "Epoch 18/50 | Train loss=0.1069, acc=51.67% | Val loss=0.0658, acc=92.55%\n",
      "Epoch 19/50 | Train loss=0.0990, acc=61.17% | Val loss=0.0651, acc=95.74%\n",
      "Epoch 20/50 | Train loss=0.1007, acc=64.27% | Val loss=0.0530, acc=98.94%\n",
      "Epoch 21/50 | Train loss=0.0999, acc=53.34% | Val loss=0.0626, acc=90.43%\n",
      "Epoch 22/50 | Train loss=0.0969, acc=54.51% | Val loss=0.0590, acc=95.74%\n",
      "Epoch 23/50 | Train loss=0.1009, acc=55.75% | Val loss=0.0538, acc=98.94%\n",
      "Epoch 24/50 | Train loss=0.0871, acc=60.49% | Val loss=0.0536, acc=98.94%\n",
      "Epoch 25/50 | Train loss=0.0979, acc=60.13% | Val loss=0.0544, acc=97.87%\n",
      "Epoch 26/50 | Train loss=0.0962, acc=57.35% | Val loss=0.0527, acc=97.87%\n",
      "Epoch 27/50 | Train loss=0.1014, acc=57.01% | Val loss=0.0555, acc=97.87%\n",
      "Early stopping at epoch 27\n",
      "Training complete. Best validation accuracy: 98.94%\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "for epoch in range(1, TOTAL_EPOCHS+1):\n",
    "    model.train()\n",
    "    running_loss = running_corr = 0\n",
    "    optimizer.zero_grad()\n",
    "    for i, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        mixed_imgs, y_a, y_b, lam = mixup_data(imgs, labels)\n",
    "        with autocast():\n",
    "            outputs = model(mixed_imgs)\n",
    "            loss = mixup_criterion(criterion, outputs, y_a, y_b, lam) / ACCUM_STEPS\n",
    "        scaler.scale(loss).backward()\n",
    "        if (i+1) % ACCUM_STEPS == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item() * ACCUM_STEPS\n",
    "        preds = outputs.argmax(1)\n",
    "        running_corr += (lam * (preds==labels).sum().item() +\n",
    "                         (1-lam) * (preds==labels[torch.randperm(labels.size(0)).to(device)]).sum().item())\n",
    "\n",
    "    train_loss = running_loss / n_train\n",
    "    train_acc  = running_corr / n_train * 100\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = val_corr = 0\n",
    "    with torch.no_grad(), autocast():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            val_corr += (outputs.argmax(1)==labels).sum().item()\n",
    "    val_loss /= n_val\n",
    "    val_acc  = val_corr / n_val * 100\n",
    "\n",
    "    early_stopper(val_acc)\n",
    "    print(f\"Epoch {epoch}/{TOTAL_EPOCHS} | Train loss={train_loss:.4f}, acc={train_acc:.2f}% | \"\n",
    "          f\"Val loss={val_loss:.4f}, acc={val_acc:.2f}%\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_vgg16_ecg_processed_green.pth\")\n",
    "        print(\" → New best model saved!\")\n",
    "    if early_stopper.early_stop:\n",
    "        print(f\"Early stopping at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "print(f\"Training complete. Best validation accuracy: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b07d48b-7daa-4aed-afb6-e0193759a063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FireFly\\AppData\\Local\\Temp\\ipykernel_10204\\4110255428.py:4: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.84%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_vgg16_ecg_processed_green.pth\"))\n",
    "model.eval()\n",
    "test_corr = 0\n",
    "with torch.no_grad(), autocast():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        test_corr += (outputs.argmax(1)==labels).sum().item()\n",
    "test_acc = test_corr / n_test * 100\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecae465-3099-4b47-96af-f85182c9735d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
